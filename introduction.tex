\tab Social media applications (such as Facebook) allow users to connect with people from around the world, giving them the ability to maintain connections to friends and family regardless of distance, as well as meet new people and form new friendships and relationships. These types of connections were difficult, if not impossible, thirty or more years ago. As a result, more personal information about users are ending up online in order to make people easier to find. This can create privacy concerns and open up the potential for abuse and leaks in information. Larger networks of friends increases the risk of sensitive information being revealed as well as potential conflict between connections a user may have in common, yet are not connected to each other (thus are unlikely to be friends or associates with each other). 
\\
\tab Through the use of customized privacy filters, users can choose the exact audience they wish to share their posts with in order to minimize who has access to personal data and information (such as sharing personal photographs with only close friends and family), or filter out others who may take offense over hot-button issues (e.g. sharing a news article in support of a particular political candidate). Privacy filters allow users greater control over their content and their intended audience, yet filters are not always easy to use or remember, introducing the possibility of user error.\cite{naini2015analyzing}
\\
\tab We propose a Chrome browser extension that, upon the user submitting the contents to be posted to Facebook, would analyze the contents searching for key words that have been defined in a rules dictionary, apply a weighted score based on the rules, and if the score is over a set threshold, the user is queried if they want to apply the defined privacy filter to the content before posting it. Alternatively, the user can set the privacy filter to automatically apply (without querying) if the threshold is exceeded. This would decrease the risk of inadvertently posting sensitive or controversial topics without at least first reminding the user of the contents and privacy filter.
\\
\tab The filters themselves would require personalization by the user, while the rules defined dictionary could be preset with default settings of the more popular controversial topics. The user can then add, remove and edit more rules, as well as set a priority level (which rules take precedence over others in the case of multiple rules matching) and the threshold level (what scoring is required to trigger the filter when a rule is matched).
